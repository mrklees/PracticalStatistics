{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression Models.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrklees/PracticalStatistics/blob/master/Regression_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "w_d9MORIfjza",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Regression Modelling\n",
        "\n",
        "### Don't Forget to Run All (Ctrl+F9)\n",
        "### Alex! Press the Record Button!!!\n",
        "\n",
        "\n",
        "By the end of the session participants will...\n",
        "\n",
        "* Review Expectation and Variance\n",
        "* Review the concept of a joint distribution\n",
        "* \n",
        "\n",
        "## Language Repository\n",
        "These are some key terms that I will throw around a lot.  You can always review their definitions here or [go back to the notebook on Statistical Testing & p-values to review.](https://colab.research.google.com/drive/15GQcjwz1TlVOOZfxiYakS1fAl3-3BiJA)\n",
        "\n",
        "**Expected Value: ** This is the average! It's the long-run average value of repetitions of the same experiment. \n",
        "\n",
        "**Variance:** This is a measure of how spread out a distribution is from its mean.  The greater the variance, the futher values fall from its mean.  \n",
        "\n",
        "**Standard Deviation:** This is really just the square root of the variance: $\\text{std dev}(X) = \\sqrt{Var(X)}$, and thus it behaves very similarly to variance.  The greater the standard deviation, the futher values fall from its mean.  It is often used in the context of normally distributed data because of how nicely a standard deviation partitions the normal distribution, per the obligatory graph:\n",
        "\n",
        "![Obligatory Graph](https://www.biologyforlife.com/uploads/2/2/3/9/22392738/sd2_orig.png)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "bwTnA1BkfzOO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Motivating Today with Simpson's Paradox\n",
        "\n",
        "In the last session, we learned about methods which allows us to directly compare two different variables, like focus list status and assessment scores.  And, ignore the fact that I spoke at length about why you shouldn't really use those mothods, you might wonder why we don't just stop there.  Why work up to more complex models?\n",
        "\n",
        "We will start off with a small example that gets at this idea.  It involves a very simple table of data.  Suppose we did some trial on the effectiveness of a drug on the risk of heart attacks. The data is summarized below.\n",
        "\n",
        "| | Control - Heart Attacks | Control - Total Participants | Treatment - Heart Attacks | Treatment - Total Participants+ |\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "|Female|1|20|3|40|\n",
        "|Male|12|40|8|20|\n",
        "\n",
        "The paradox here comes from the two stories that I can tell with this table of data.  \n",
        "\n",
        "The **first story** is about a fantastic new drug! In a clinical trial of 120 participants, participants who tool the experimental drug experienced heart attacks had about a 15% reduction in heart attacks.  Talk to your doctor today!\n",
        "\n",
        "However the **second story** is an investigative journlism piece about a dangerous drug put out on the market.  When *looking at men and women separately* it turns that in either case it *raises your risk of heart attack* by about 25% (for men) to 50% (for women). Obviously a drug which is bad for both men and women should be banned. \n",
        "\n",
        "To be clear, these calculations are really just simple percentages. In the first story, we just pretend like the data isn't segmented.  So $\\frac{13}{60}=21.6\\%$ participants in the control and $\\frac{11}{60}=18.3\\%$ in the treatment group experienced heart attacks. Of course I then presented their ratio, because it's a much more marketable number üëç.\n",
        "\n",
        "Since the second story is symmetrical, I'll just talk about women.  In the control group, $\\frac{1}{20}=5\\%$ of women experience heart attacks where as $\\frac{3}{40}=7.5\\%$ women in the treatment group experienced heart attacks. A similar increase was seen for men. \n",
        "\n",
        "There is a lot within Simpson's Paradox.  It was published over 60 years ago and still is the topic of some conversation. What I really want you to get from this is: this is what confounding can look like.  If we just measure effects directly then there is a risk that what we measure could not only be different from the true effect, but could be in the completely wrong direction. "
      ]
    },
    {
      "metadata": {
        "id": "UsB6SDSaIf__",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Imports and Global Variables (run this cell first)  { display-mode: \"form\" }\n",
        "#@markdown This sets the warning status (default is `ignore`, since this notebook runs correctly)\n",
        "warning_status = \"ignore\" #@param [\"ignore\", \"always\", \"module\", \"once\", \"default\", \"error\"]\n",
        "import warnings\n",
        "warnings.filterwarnings(warning_status)\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(warning_status, category=DeprecationWarning)\n",
        "    warnings.filterwarnings(warning_status, category=UserWarning)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "#@markdown This sets the styles of the plotting (default is styled like plots from [FiveThirtyeight.com](https://fivethirtyeight.com/))\n",
        "matplotlib_style = 'fivethirtyeight' #@param ['fivethirtyeight', 'bmh', 'ggplot', 'seaborn', 'default', 'Solarize_Light2', 'classic', 'dark_background', 'seaborn-colorblind', 'seaborn-notebook']\n",
        "import matplotlib.pyplot as plt; plt.style.use(matplotlib_style)\n",
        "%matplotlib inline\n",
        "import seaborn as sns; sns.set_context('notebook')\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.api import OLS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fngP6ohTWJzv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "8ac01270-6a97-448b-83c2-519330ad5bcf"
      },
      "cell_type": "code",
      "source": [
        "#@title Read the Data from the Web { display-mode: \"form\" }\n",
        "data_url = 'https://impactblob.blob.core.windows.net/public/anon_hmh.csv'\n",
        "data = pd.read_csv(data_url)\n",
        "data.head()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GRADE_ID_NUMERIC</th>\n",
              "      <th>OFFICIALFLLIT</th>\n",
              "      <th>OFFICIALFLMTH</th>\n",
              "      <th>FL_LIT_MET_DOSAGE</th>\n",
              "      <th>FL_MTH_MET_DOSAGE</th>\n",
              "      <th>litassess_pre_value_num</th>\n",
              "      <th>LITASSESS_RAWCHANGE</th>\n",
              "      <th>LITASSESS_SRITARGET</th>\n",
              "      <th>mathassess_pre_value_num</th>\n",
              "      <th>MathAssess_RAWCHANGE</th>\n",
              "      <th>SMI_TARGET</th>\n",
              "      <th>AnonId</th>\n",
              "      <th>SiteId</th>\n",
              "      <th>SchoolId</th>\n",
              "      <th>att_pre_value</th>\n",
              "      <th>att_post_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>505.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>2634048971</td>\n",
              "      <td>1</td>\n",
              "      <td>59</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>505.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>2405496161</td>\n",
              "      <td>1</td>\n",
              "      <td>59</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>610.0</td>\n",
              "      <td>305.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>2627617999</td>\n",
              "      <td>1</td>\n",
              "      <td>59</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>695.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>1437215014</td>\n",
              "      <td>1</td>\n",
              "      <td>59</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>610.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>461103962</td>\n",
              "      <td>1</td>\n",
              "      <td>59</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   GRADE_ID_NUMERIC  OFFICIALFLLIT  OFFICIALFLMTH  FL_LIT_MET_DOSAGE  \\\n",
              "0                 7              0              0                NaN   \n",
              "1                 7              0              0                NaN   \n",
              "2                 7              0              0                NaN   \n",
              "3                 8              0              0                NaN   \n",
              "4                 8              0              0                NaN   \n",
              "\n",
              "   FL_MTH_MET_DOSAGE  litassess_pre_value_num  LITASSESS_RAWCHANGE  \\\n",
              "0                NaN                      NaN                  NaN   \n",
              "1                NaN                      NaN                  NaN   \n",
              "2                NaN                      NaN                  NaN   \n",
              "3                NaN                      NaN                  NaN   \n",
              "4                NaN                      NaN                  NaN   \n",
              "\n",
              "   LITASSESS_SRITARGET  mathassess_pre_value_num  MathAssess_RAWCHANGE  \\\n",
              "0                  NaN                     505.0                 130.0   \n",
              "1                  NaN                     505.0                 290.0   \n",
              "2                  NaN                     610.0                 305.0   \n",
              "3                  NaN                     695.0                 135.0   \n",
              "4                  NaN                     610.0                  75.0   \n",
              "\n",
              "   SMI_TARGET      AnonId  SiteId  SchoolId  att_pre_value  att_post_value  \n",
              "0       150.0  2634048971       1        59            NaN             NaN  \n",
              "1       150.0  2405496161       1        59            NaN             NaN  \n",
              "2       150.0  2627617999       1        59            NaN             NaN  \n",
              "3       150.0  1437215014       1        59            NaN             NaN  \n",
              "4       150.0   461103962       1        59            NaN             NaN  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "XwtSwre9WSzW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "ca78fe79-be37-4ab6-a59c-f36e56039154"
      },
      "cell_type": "code",
      "source": [
        "#@title Descriptive Stats to Reference { display-mode: \"form\" }\n",
        "def describe_nulls(data):\n",
        "    desc = data.describe(include=data.dtypes.unique())\n",
        "    desc.loc['% Null'] = data.isna().sum() / data.shape[0]\n",
        "    return desc\n",
        "describe_nulls(data)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GRADE_ID_NUMERIC</th>\n",
              "      <th>OFFICIALFLLIT</th>\n",
              "      <th>OFFICIALFLMTH</th>\n",
              "      <th>FL_LIT_MET_DOSAGE</th>\n",
              "      <th>FL_MTH_MET_DOSAGE</th>\n",
              "      <th>litassess_pre_value_num</th>\n",
              "      <th>LITASSESS_RAWCHANGE</th>\n",
              "      <th>LITASSESS_SRITARGET</th>\n",
              "      <th>mathassess_pre_value_num</th>\n",
              "      <th>MathAssess_RAWCHANGE</th>\n",
              "      <th>SMI_TARGET</th>\n",
              "      <th>AnonId</th>\n",
              "      <th>SiteId</th>\n",
              "      <th>SchoolId</th>\n",
              "      <th>att_pre_value</th>\n",
              "      <th>att_post_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6620.000000</td>\n",
              "      <td>6620.000000</td>\n",
              "      <td>6620.000000</td>\n",
              "      <td>2651.000000</td>\n",
              "      <td>2784.000000</td>\n",
              "      <td>4478.000000</td>\n",
              "      <td>3762.000000</td>\n",
              "      <td>4123.000000</td>\n",
              "      <td>4633.000000</td>\n",
              "      <td>3879.000000</td>\n",
              "      <td>3262.000000</td>\n",
              "      <td>6.620000e+03</td>\n",
              "      <td>6620.000000</td>\n",
              "      <td>6620.000000</td>\n",
              "      <td>1290.000000</td>\n",
              "      <td>1156.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.344411</td>\n",
              "      <td>0.401964</td>\n",
              "      <td>0.421148</td>\n",
              "      <td>0.836288</td>\n",
              "      <td>0.858477</td>\n",
              "      <td>596.491291</td>\n",
              "      <td>53.556087</td>\n",
              "      <td>105.724715</td>\n",
              "      <td>459.830563</td>\n",
              "      <td>81.768497</td>\n",
              "      <td>126.587983</td>\n",
              "      <td>2.152367e+09</td>\n",
              "      <td>1.659517</td>\n",
              "      <td>37.133082</td>\n",
              "      <td>0.903720</td>\n",
              "      <td>0.888573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.944957</td>\n",
              "      <td>0.490332</td>\n",
              "      <td>0.493781</td>\n",
              "      <td>0.370084</td>\n",
              "      <td>0.348623</td>\n",
              "      <td>341.226084</td>\n",
              "      <td>159.348106</td>\n",
              "      <td>82.842579</td>\n",
              "      <td>245.442909</td>\n",
              "      <td>207.451570</td>\n",
              "      <td>57.186226</td>\n",
              "      <td>1.239760e+09</td>\n",
              "      <td>1.086982</td>\n",
              "      <td>18.407459</td>\n",
              "      <td>0.087059</td>\n",
              "      <td>0.105393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-747.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>-300.000000</td>\n",
              "      <td>-1070.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>7.713890e+05</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.211000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>350.250000</td>\n",
              "      <td>-25.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>270.000000</td>\n",
              "      <td>-45.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>1.062132e+09</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.868500</td>\n",
              "      <td>0.844000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>648.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>455.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>2.159307e+09</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>0.923500</td>\n",
              "      <td>0.921000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>848.750000</td>\n",
              "      <td>138.750000</td>\n",
              "      <td>133.000000</td>\n",
              "      <td>640.000000</td>\n",
              "      <td>215.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>3.228741e+09</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>0.966000</td>\n",
              "      <td>0.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1540.000000</td>\n",
              "      <td>1048.000000</td>\n",
              "      <td>364.000000</td>\n",
              "      <td>1190.000000</td>\n",
              "      <td>845.000000</td>\n",
              "      <td>260.000000</td>\n",
              "      <td>4.294937e+09</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>% Null</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.599547</td>\n",
              "      <td>0.579456</td>\n",
              "      <td>0.323565</td>\n",
              "      <td>0.431722</td>\n",
              "      <td>0.377190</td>\n",
              "      <td>0.300151</td>\n",
              "      <td>0.414048</td>\n",
              "      <td>0.507251</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.805136</td>\n",
              "      <td>0.825378</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        GRADE_ID_NUMERIC  OFFICIALFLLIT  OFFICIALFLMTH  FL_LIT_MET_DOSAGE  \\\n",
              "count        6620.000000    6620.000000    6620.000000        2651.000000   \n",
              "mean            7.344411       0.401964       0.421148           0.836288   \n",
              "std             1.944957       0.490332       0.493781           0.370084   \n",
              "min             3.000000       0.000000       0.000000           0.000000   \n",
              "25%             6.000000       0.000000       0.000000           1.000000   \n",
              "50%             8.000000       0.000000       0.000000           1.000000   \n",
              "75%             9.000000       1.000000       1.000000           1.000000   \n",
              "max            10.000000       1.000000       1.000000           1.000000   \n",
              "% Null          0.000000       0.000000       0.000000           0.599547   \n",
              "\n",
              "        FL_MTH_MET_DOSAGE  litassess_pre_value_num  LITASSESS_RAWCHANGE  \\\n",
              "count         2784.000000              4478.000000          3762.000000   \n",
              "mean             0.858477               596.491291            53.556087   \n",
              "std              0.348623               341.226084           159.348106   \n",
              "min              0.000000                 0.000000          -747.000000   \n",
              "25%              1.000000               350.250000           -25.000000   \n",
              "50%              1.000000               648.000000            41.000000   \n",
              "75%              1.000000               848.750000           138.750000   \n",
              "max              1.000000              1540.000000          1048.000000   \n",
              "% Null           0.579456                 0.323565             0.431722   \n",
              "\n",
              "        LITASSESS_SRITARGET  mathassess_pre_value_num  MathAssess_RAWCHANGE  \\\n",
              "count           4123.000000               4633.000000           3879.000000   \n",
              "mean             105.724715                459.830563             81.768497   \n",
              "std               82.842579                245.442909            207.451570   \n",
              "min                3.000000               -300.000000          -1070.000000   \n",
              "25%               51.000000                270.000000            -45.000000   \n",
              "50%               70.000000                455.000000             95.000000   \n",
              "75%              133.000000                640.000000            215.000000   \n",
              "max              364.000000               1190.000000            845.000000   \n",
              "% Null             0.377190                  0.300151              0.414048   \n",
              "\n",
              "         SMI_TARGET        AnonId       SiteId     SchoolId  att_pre_value  \\\n",
              "count   3262.000000  6.620000e+03  6620.000000  6620.000000    1290.000000   \n",
              "mean     126.587983  2.152367e+09     1.659517    37.133082       0.903720   \n",
              "std       57.186226  1.239760e+09     1.086982    18.407459       0.087059   \n",
              "min       20.000000  7.713890e+05     1.000000     1.000000       0.300000   \n",
              "25%       90.000000  1.062132e+09     1.000000    21.000000       0.868500   \n",
              "50%      100.000000  2.159307e+09     1.000000    43.000000       0.923500   \n",
              "75%      150.000000  3.228741e+09     2.000000    51.000000       0.966000   \n",
              "max      260.000000  4.294937e+09     5.000000    65.000000       1.000000   \n",
              "% Null     0.507251  0.000000e+00     0.000000     0.000000       0.805136   \n",
              "\n",
              "        att_post_value  \n",
              "count      1156.000000  \n",
              "mean          0.888573  \n",
              "std           0.105393  \n",
              "min           0.211000  \n",
              "25%           0.844000  \n",
              "50%           0.921000  \n",
              "75%           0.960000  \n",
              "max           1.000000  \n",
              "% Null        0.825378  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "_lWAOH6QZjc3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Regression\n",
        "\n",
        "This is a typical section where people bring out formulas and abstract graphs to try to explain this topic... but in the flavor of practical statistics we're going to talk about regression in terms of a different conceptual model.  One which will hopefully allow us to worry a little bit less about the math.  The reason that I feel that I can get away with this is that *most modern statistical interfaces* allow you to operate at this level of abstraction with this kind of conceptual framework instead of having to concern yourself with the details. Of course there is some variation in the aesthetics, but largely they are all the same.\n",
        "\n",
        "## Regression as a Framework for Prediction\n",
        "\n",
        "In our framework, regression is all about being able to take some data and make predictions about future data. In this context, we'll use a few new pieces of language with somewhat specific meanings.  Let's go through the language with some explanation. \n",
        "\n",
        "**Features**: The data we use to make predictions.  For a student, this might be things like grade, school, focus list student, etc...  We hope that this data contains information about the **outcome** we want to predict.\n",
        "\n",
        "**Outcomes**: The variable we want to make predictions about.  For example, we've made predictions about how much a student will improve on a math assessment. \n",
        "\n",
        "**Model**:  A **model** is used to make predictions about **outcomes**. Generally speaking, it is simply some mathematical device which tells us how to multiply and add our data to get **predictions** about our **outcomes**. \n",
        "\n",
        "The general goal of Regression is to *fit* (or *train*) **models** on **features** where the **outcomes** are known, and then use them to make predictions on new data where the **outcomes** aren't known.  In the last session we previewed a formula notation which expresses this idea.  In its full form it might look like:\n",
        "$$ \\text{Outcomes} \\sim \\text{Model(Features)}$$\n",
        "Although, we dropped the model portion, because it doesn't really tell us much.  So we're just left with:\n",
        "$$ \\text{Outcomes} \\sim \\text{Features}$$\n",
        "\n",
        "### Fitting Model: What do we need to understand for Practical Statistics?\n",
        "\n",
        "For the purposes of Pratical Statistics, we will acknowledge that these models exist and talk *exclusively* about how to use them.  Unfortunately, going much further into how a model is trained requires going into some calculus, so we will skate around the topic.  Instead, since you can use software prepared by professionals you can largely trust that *as long as you specify the model correctly*, the software will not make a mistake in fitting the model correctly. What I mean by *specifying the model correctly* will be one of the key subjects we discuss. "
      ]
    },
    {
      "metadata": {
        "id": "EViiFp4wWsDg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "ef4c0fd8-5657-4e01-af3b-bcddb6a1e852"
      },
      "cell_type": "code",
      "source": [
        "#@title Regression Choose Your Own Adventure {run: 'auto', display-mode: \"form\"} \n",
        "#@markdown This tool will allow you fit nearly any possible linear model from the data.  Start by selecting which column will be the **Outcome**.  I would recommend `MathAssess_RAWCHANGE` or `LITASSESS_RAWCHANGE`, but I've left every column available. \n",
        "Outcomes = \"MathAssess_RAWCHANGE\" #@param ['GRADE_ID_NUMERIC', 'OFFICIALFLLIT', 'OFFICIALFLMTH', 'FL_LIT_MET_DOSAGE', 'FL_MTH_MET_DOSAGE', 'litassess_pre_value_num', 'LITASSESS_RAWCHANGE', 'LITASSESS_SRITARGET', 'mathassess_pre_value_num', 'MathAssess_RAWCHANGE', 'SMI_TARGET', 'AnonId', 'SiteId', 'SchoolId', 'att_pre_value', 'att_post_value']\n",
        "\n",
        "#@markdown Then select which columns of data should be included in your model!  Sorry for the rough interface, but Colab hasn't published a better one yet. \n",
        "GRADE_ID_NUMERIC = False #@param {type:\"boolean\"}\n",
        "OFFICIALFLLIT = False #@param {type:\"boolean\"}\n",
        "OFFICIALFLMTH = False #@param {type:\"boolean\"}\n",
        "FL_LIT_MET_DOSAGE = False #@param {type:\"boolean\"}\n",
        "FL_MTH_MET_DOSAGE = False #@param {type:\"boolean\"}\n",
        "litassess_pre_value_num = False #@param {type:\"boolean\"}\n",
        "LITASSESS_RAWCHANGE = False #@param {type:\"boolean\"}\n",
        "LITASSESS_SRITARGET = False #@param {type:\"boolean\"}\n",
        "mathassess_pre_value_num = False #@param {type:\"boolean\"}\n",
        "MathAssess_RAWCHANGE = False #@param {type:\"boolean\"}\n",
        "SMI_TARGET = False #@param {type:\"boolean\"}\n",
        "SiteId = False #@param {type:\"boolean\"}\n",
        "SchoolId = False #@param {type:\"boolean\"}\n",
        "att_pre_value = True #@param {type:\"boolean\"}\n",
        "att_post_value = False #@param {type:\"boolean\"}\n",
        "\n",
        "colnames= np.array([\n",
        "           'GRADE_ID_NUMERIC', 'OFFICIALFLLIT', 'OFFICIALFLMTH',\n",
        "           'FL_LIT_MET_DOSAGE', 'FL_MTH_MET_DOSAGE', 'litassess_pre_value_num',\n",
        "           'LITASSESS_RAWCHANGE', 'LITASSESS_SRITARGET',\n",
        "           'mathassess_pre_value_num', 'MathAssess_RAWCHANGE', 'SMI_TARGET',\n",
        "           'SiteId', 'SchoolId', 'att_pre_value', 'att_post_value'])\n",
        "\n",
        "responses = np.array([GRADE_ID_NUMERIC, OFFICIALFLLIT, OFFICIALFLMTH,\n",
        "FL_LIT_MET_DOSAGE, FL_MTH_MET_DOSAGE, litassess_pre_value_num,\n",
        "LITASSESS_RAWCHANGE, LITASSESS_SRITARGET,\n",
        "mathassess_pre_value_num, MathAssess_RAWCHANGE, SMI_TARGET,\n",
        "SiteId, SchoolId, att_pre_value, att_post_value])\n",
        "\n",
        "# Get Selected Features\n",
        "Features = list(colnames[responses])\n",
        "\n",
        "try:\n",
        "    assert Outcomes not in Features\n",
        "    \n",
        "    model_string = Outcomes + \" ~ \" + ' + '.join(Features)\n",
        "    print(f\"Current Model: {model_string}\")\n",
        "    print(\"Fitting... Be aware that null data will be dropped...\")\n",
        "\n",
        "    model = OLS(endog=data[Outcomes], exog=sm.add_constant(data[Features]), missing='drop').fit()\n",
        "    print(\"Done... Returning Summary...\")\n",
        "    print(model.summary())\n",
        "except AssertionError:\n",
        "    print(\"Your outcome variable is also selected as a feature you silly goose!\")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current Model: MathAssess_RAWCHANGE ~ att_pre_value\n",
            "Fitting... Be aware that null data will be dropped...\n",
            "Done... Returning Summary...\n",
            "                             OLS Regression Results                             \n",
            "================================================================================\n",
            "Dep. Variable:     MathAssess_RAWCHANGE   R-squared:                       0.004\n",
            "Model:                              OLS   Adj. R-squared:                  0.003\n",
            "Method:                   Least Squares   F-statistic:                     3.991\n",
            "Date:                  Mon, 15 Apr 2019   Prob (F-statistic):             0.0460\n",
            "Time:                          21:38:29   Log-Likelihood:                -7164.6\n",
            "No. Observations:                  1053   AIC:                         1.433e+04\n",
            "Df Residuals:                      1051   BIC:                         1.434e+04\n",
            "Df Model:                             1                                         \n",
            "Covariance Type:              nonrobust                                         \n",
            "=================================================================================\n",
            "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------\n",
            "const          -114.1465     72.559     -1.573      0.116    -256.523      28.230\n",
            "att_pre_value   158.9283     79.554      1.998      0.046       2.825     315.032\n",
            "==============================================================================\n",
            "Omnibus:                       61.344   Durbin-Watson:                   1.882\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              119.053\n",
            "Skew:                          -0.393   Prob(JB):                     1.41e-26\n",
            "Kurtosis:                       4.447   Cond. No.                         21.6\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J84xOM1ntgkR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Makes all the models](https://i.imgflip.com/2ynvwj.jpg)\n",
        "![Which one is right though?](https://i.imgflip.com/2ynw4z.jpg)\n",
        "\n",
        "# All Models Are Wrong\n",
        "\n",
        "Now that we have the ability to generate in fact thousands of different models, we need some method of choosing between them. It's at about this point that I should offer a piece of wisdom [attributed to statistician George Box](https://en.wikipedia.org/wiki/All_models_are_wrong): *\"All models are wrong, but some are useful.\"*  We aren't fortune tellers.  As much as we would like, we cannot predict the future and our puny mathematics cannot fully represent natural processes (yet).  So we start from the premise that our models are at best approximations, but thankfully the full effort of statisticians in the last century have gone into showing that we can build some good approximations and that there are some processes we can utilize to get there.\n",
        "\n",
        "## Process for Finding Good Models\n",
        "\n",
        "Finding good models is ultimately a iterative process.  Like a good scientist, we have to be consistently skeptical of our current model, knowing that there is probably a better one out there. I like thinking about this as a process, summed up in this short diagram:\n",
        "\n",
        "![Box's Loop](https://cdn-images-1.medium.com/max/800/0*k1g-sYQ0QTOtOAyK.png)\n",
        "\n",
        "The [developers of Edward call this Box's Loop](http://www.cs.columbia.edu/~blei/fogm/2015F/notes/intro.pdf), and as you can see it consists of a three step process which constantly repeats.\n",
        "\n",
        "  1.  **Model:** Our model represents our beliefs about how the world works.  We want to consistantly return to the question \"what process generated the data that I'm observing\", and try to make sure that our model is as consistent with that our beliefs about that process as possible.\n",
        "  2.  **Infer:** This is a fancy word for fitting a model with data.  \n",
        "  3.  **Criticize:** Does out model make reasonable predictions?  Is it more accurate than a coin flip?\n",
        "  \n",
        "## Model Criticism\n",
        "\n",
        "As we hinted above, one strategy for model criticism is to examine it's accuracy. What *accuracy* actually means depends on the outcome that we're trying to predict, but rest assured that there are good solutions for which ever outcome you choose. \n",
        "\n",
        "The results that we're getting  from python are actually summarizing a bunch of different accuracy measurements, so let's talk a little bit about what they mean. These are the results that are drawn from the top right section of the results summary.  \n",
        "\n",
        "| Measure | Example Outcome | \n",
        "|----------------|-----------|\n",
        "|R-squared| 0.01 | \n",
        "|Adj. R-squared| 0.009|\n",
        "|F-statistic|3.990|\n",
        "|Prob (F-statistic)|0.046|\n",
        "|Log-Likelihood|-7164.6|\n",
        "|AIC|1.433e+04|\n",
        "|BIC|1.434e+04|\n",
        "\n",
        "  * [$R^2$ and $\\text{Adj. } R^2$](https://en.wikipedia.org/wiki/Coefficient_of_determination): More formally called the coefficient of determination, this values is the percentage of the outputs variance that's explained by the features of the model. Values can be between 0 and 1, with 1 being 100% of the variance of the output being explined by the features.  With $R^2 = 1$, our model should always make correct predictions. The *adjusted* value is very similar and tries to account for certain types of bias.  It will typically be very close to the $R^2$ value, but is a good one to look at when comparing models. \n",
        "  * [F-statistic and Prob (F-statistic)](https://en.wikipedia.org/wiki/F-test): This is a built in statistical test which essentially compares the model that you've proposed to one which has no features in it.  If the Prob (F-statistic) (i.e. the p-value) is sufficiently low, then you might believe that this model with its proposed features are better than a model without them. \n",
        "  * [Log-Likelihood](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation): Without going into detail, when the model is fit it is trying to maximize this value.  So between two models, the higher the log-likelihood the better the prediction accuracy. \n",
        "  * [AIC and BIC](https://en.wikipedia.org/wiki/Akaike_information_criterion): It's not so important how these are calculated as I don't think they offer any greater interpritability, but the smaller the value the better when choosing your model.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "EnPPJmJRvKRQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Mini-Hackathon Time\n",
        "\n",
        "With whatever time we have left your job is to explore the data and find the best sets of predictors for either Math or ELA assessment change. \n",
        "\n",
        "[And as usual, please leave me some feedback! It's appreciated :)](https://forms.office.com/Pages/ResponsePage.aspx?id=n4nHpSnR9kisiI-X82badMFC4tEHX8lCm8qe3Orb0kdUQkw2TkQxUFJEWjlCRElPVlJQWktVRlQ0QiQlQCN0PWcu) "
      ]
    }
  ]
}